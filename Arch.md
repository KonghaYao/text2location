# 中文地址解析系统架构文档

## 1. 系统概述

本系统旨在设计一个高效的中文地址解析服务，能够将用户输入的非标准中文地址字符串（如“北京市朝阳区三里屯”）匹配到包含 5 万
条数据的标准地址库中。系统核心能力包括快速检索、模糊匹配、支持地址要素省略及顺序颠倒处理。

## 2. 核心架构

### 2.1 架构流程

系统主要包含以下几个处理阶段：

1. **输入处理**: 接收原始中文地址字符串。
2. **预处理 (Preprocessing)**: 清洗、标准化及分词。
3. **索引 (Indexing)**: 构建倒排索引以加速查找。
4. **匹配 (Matching)**: 基于 TF-IDF/BM25 或向量相似度进行打分排序。
5. **输出**: 返回相似度最高的 Top-K 标准地址及其 ID。

### 2.2 核心组件

-   **分词器 (Tokenizer)**: 负责将连续文本切分为有意义的地址要素（省、市、区、街道等），避免低效的字符级匹配。
-   **索引器 (Indexer)**: 构建倒排索引 (Inverted Index)，建立 `词 -> 文档ID` 的映射。
-   **匹配器 (Matcher)**: 核心算法组件，计算输入与库中地址的相似度。
-   **地址库**: 存储预处理后的标准地址数据（约 5 万条）。

## 3. 数据预处理

在构建索引和查询前，数据需经过严格预处理：

-   **结构化**: 尽可能将地址文本拆分为国家、省、市、区、街道、门牌号等结构化字段。
-   **标准化**:
    -   去除无意义标点和空白字符。
    -   统一简繁体（使用 OpenCC）。
    -   数字归一化（如 "一号楼" -> "1 号楼"）。
-   **中文分词**:
    -   **工具**: 推荐使用 `Jieba` (轻量、生态好) 或 `HanLP` (NER 实体识别能力强)。
    -   **自定义词典**: 必须加载地名库（如“三里屯”、“SOHO”），防止专有名词被错误切分。

## 4. 索引构建

-   **倒排索引**: 将地址库视为文档集合。
-   **权重计算**:
    -   使用 **TF-IDF** 或 **BM25** 算法。
    -   **TF (Term Frequency)**: 词在当前地址中出现的频率。
    -   **IDF (Inverse Document Frequency)**: 词在所有地址中出现的稀有度。
    -   **策略**: 降低“省”、“市”、“中国”等高频通用词的权重，提升具体路名、小区名等稀有词的权重。

## 5. 查询与匹配策略

-   **向量相似度**: 将查询串和库中地址转换为向量，计算余弦相似度 (Cosine Similarity)。
-   **模糊匹配**:
    -   **顺序颠倒**: 通过词袋模型 (Bag of Words) 或多字段索引权重（省市权重 > 门牌权重）解决（如“朝阳区北京市”匹配“北京
        市朝阳区”）。
    -   **容错**: 支持 Fuzzy Query 处理少量错别字。
-   **结果过滤**: 返回得分最高的 Top-3 或 Top-5，并设置相似度阈值（如 > 0.8）过滤低质量匹配。

## 6. 技术选型

### 方案 A: Elasticsearch (通用生产级)

-   **特点**: 成熟的分布式搜索引擎，生态完善。
-   **配置**: ES + `elasticsearch-analysis-ik` 中文分词插件。
-   **优势**: 开箱即用，支持复杂的 Query DSL。
-   **劣势**: 资源占用较重 (JVM)，对仅 5 万条数据来说略显臃肿。

### 方案 B: Python 自定义实现 (原型验证)

-   **栈**: Jieba + Scikit-learn / Gensim。
-   **特点**: 使用内存字典构建倒排索引或计算 TF-IDF 矩阵。
-   **优势**: 实现简单，便于理解算法。
-   **劣势**: 查询性能和并发能力不如专用引擎。

### 方案 C: Rust + Tantivy (推荐方案)

-   **简介**: Tantivy 是一个受 Lucene 启发的 Rust 高性能全文搜索引擎库。
-   **为什么选择 Tantivy**:
    1.  **高性能**: 纯 Rust 实现，查询响应 <100ms，支持 SIMD 加速，基于 mmap 的高效 IO。
    2.  **轻量级**: 编译为单一二进制，无 JVM 依赖，部署极其简单。
    3.  **功能完备**: 内置 BM25 评分，支持 Fuzzy Search，支持多线程索引。
    4.  **中文支持**: 可通过 `tantivy-jieba` 完美集成中文分词。
-   **实现路径**:
    -   依赖: `cargo add tantivy tantivy-jieba`
    -   流程: 定义 Schema -> 创建 IndexWriter -> 批量写入 Document -> 创建 Reader/Searcher -> 解析 Query -> Search。

## 7. 结论

鉴于项目规模（5 万条数据）及对性能和轻量化的追求，**推荐使用 Rust + Tantivy** 方案。它既能提供生产级的搜索性能，又能保持
架构的简洁性。
